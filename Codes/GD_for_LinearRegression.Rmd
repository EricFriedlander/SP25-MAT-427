---
title: "Gradient Descent for Linear Regression"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

#### ---------------------------------------------------------------------------
### Exploratory Data Analysis (EDA)

```{r}
outlets <- readRDS("outlets.rds")   # load dataset
```


```{r}
library(GGally)

ggpairs(data = outlets)    # correlation plot/matrix
```


```{r}
# scatterplot

ggplot(data = outlets) +
  geom_point(mapping = aes(x = population, y = profit))    
```



#### ---------------------------------------------------------------------------
### Implement Gradient Descent

```{r}
# define variables

x = outlets$population   # input/predictor
y = outlets$profit       # response
```


```{r}
# define necessary functions

# calculates y-hats
predict <- function(x, b0, b1)
{
  return(b0 + b1 * x)
}


# calculates MSE (loss/cost)
loss_mse <- function(predictions, y)
{
  residuals = predictions - y
  return(mean(residuals ^ 2))
}


# calculates the gradients with respect to b0 and b1
gradient <- function(x, y, predictions)
{
  dinputs = predictions - y
  db1 = 2 * mean(x * dinputs)
  db0 = 2 * mean(dinputs)
  
  return(list("db1" = db1, "db0" = db0))
}

```


```{r}
# starting values
b0 =  0
b1 =  0

# specify learning rate (also called step size)
learning_rate = 0.1

# specify number of iterations of the algorithm
niter = 50

# define objects to store results
loss_values =  rep(NA, niter)
b0_values = rep(NA, niter)
b1_values = rep(NA, niter)
```


```{r}
# gradient descent algorithm

for (epoch in 1:niter)
{
  
  predictions = predict(x, b0, b1)    # obtain predictions
  
  loss = loss_mse(predictions, y)     # calculate MSE
  
  gradients = gradient(x, y, predictions)   # obtain gradients
  db0 = gradients$db0   # gradient with respect to b0
  db1 = gradients$db1   # gradient with respect to b1
  
  
  b0 = b0 - db0 * learning_rate     # update b0
  b1 = b1 - db1 * learning_rate     # update b1
  
  
  # store resulting values to track progress
  loss_values[epoch] = loss
  b0_values[epoch] = b0
  b1_values[epoch] = b1
  
  
  # display loss to track progress
  if (epoch %% 10 == 0){print(paste0("Epoch: ",epoch, ", Loss: ", round(loss, 5)))}

}

```


```{r}
# display results as a graph

results <- data.frame(epoch = 1:niter, loss = loss_values, b0 = b0_values, b1 = b1_values)

ggplot(data = results, aes(x = epoch, y = loss)) + 
  geom_line(color="steelblue") + 
  theme_classic()
```


```{r}
# display parameter estimates after algorithm

b0    # estimated intercept   
 
b1    # estimated slope
```


```{r}
# obtain prediction for a given value of x (say 17)

predict(x = 17, b0, b1)    # this is using our 'predict' function define above
```



#### ---------------------------------------------------------------------------
### Linear Regression in R

```{r}
outlets_model <- lm(profit ~ population, data = outlets)   # build model

outlets_model    # display parameter estimates
```


```{r, fig.align='center', fig.width=8, fig.height=6}
# scatterplot with regression line

ggplot(data = outlets) +
  geom_point(mapping = aes(x = population, y = profit)) +    # create scatterplot
  geom_smooth(mapping = aes(x = population, y = profit), method = "lm", se = FALSE)   # add the regression line
```


```{r}
# obtain prediction for a given value of x (say 17)

predict.lm(outlets_model, newdata = data.frame(population = 17))   # this is using R's in-built 'predict.lm' function
```


#### ---------------------------------------------------------------------------
