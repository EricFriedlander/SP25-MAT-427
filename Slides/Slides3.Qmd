---
title: 'MATH 427: Machine Learning'
author: Eric Friedlander <br> [Much of the content in these slides have been adapted from Abhishek Chakraborty at Lawrence University]{.smaller}
format: revealjs
execute:
  echo: true
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---


```{r setup}
#| include: FALSE
library(tidyverse)
library(gridExtra)
library(modeldata)
```

## Multiple Linear Regression

- Response: $Y$
- Predictor Variables: $X_1, X_2, \ldots, X_p$
- Assume true relationship:
$$
\begin{aligned}
Y&=f(\mathbf{X}) + \epsilon\\
&=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_p X_p + \epsilon
\end{aligned}
$$
where $\beta_j$ quantifies the association between the $j^{th}$ predictor and the response.



## [Multiple Linear Regression: Estimating Parameters]{.r-fit-text} {.smaller}

- Suppose $\hat{\beta}_0, \hat{\beta}_1, \ldots, \hat{\beta}_p$ are estimates of $\beta_0, \beta_1, \ldots, \beta_p$
- Training Data:
  + Observed response: $y_i$ for $i=1,\ldots,n$
  + Observed predictors: $x_{1i}, x_{2i}, \ldots x_{pi}$ for $i=1,\ldots, n$
- Predicted response: 
$$\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1x_{1i} + \ldots + \hat{\beta}_px_{pi} \text{ for } i=1, \ldots, n$$
- Residuals: $e_i = \hat{y}_i - y_i$ for $i=1, \ldots, n$
- Mean Squared Error (MSE): $MSE =\dfrac{e^2_1+e^2_2+\ldots+e^2_n}{n}$

## [Multiple Linear Regression: Estimating Parameters]{.r-fit-text}

- **Goal:** Use *training data* to find $\hat{\beta}_0, \hat{\beta}_1, \ldots, \hat{\beta}_p$ that minimizes MSE
  + $\hat{\beta}_i$'s called **least-squares estimators**
  + Since minimizing MSE $\implies$ MSE is called **cost/loss function**
- Can use calculus or gradient descent to find $\hat{\beta}_i$'s



## Multiple Linear Regression

- **House Prices dataset:**
  + `size` is in square feet
  + `num_bedrooms` is a count
  + `price` is in $1,000's

```{r}
house_prices <- readRDS("house_prices.rds")   # load dataset
head(house_prices, 6)   # print first 6 observations
```


## Multiple Linear Regression

Some Exploratory Data Analysis (EDA)

```{r}
library(GGally)
ggpairs(data = house_prices)   # correlation plot
```

## Multiple Linear Regression in R {.smaller}

```{r}
mlr_model <- lm(price ~ size + num_bedrooms, data = house_prices)   # fit the model
summary(mlr_model)   # produce result summaries of the model
```

## [Multiple Linear Regression: Interpreting Parameters]{.r-fit-text} {.smaller}

- $\hat{\beta}_0=89.5978$: The intercept $\implies$ a house with 0 square feet and 0 bedrooms would cost approximately \$89,598.80. Is this meaningful in context? [Not really]{.fragment .fade-in}
- $\hat{\beta}_1=0.1392$: With `num_bedrooms` remaining fixed, an additional 1 square foot of `size` leads to an increase in `price` by approximately \$139.20.
- $\hat{\beta}_2=-8.7379$: With `size` remaining fixed, an additional bedroom leads to an decrease in `price` of approximately \$8,737.90.

. . .

- Hmm.... that's a little weird...
- **Simpson's Paradox:** when relationship between two variables disappears or reverses when controlling for a third, **confounding variable**

## [Multiple Linear Regression: Interpreting Parameters]{.r-fit-text}

:::{.incremental}
- Write down our model in mathematical notation
- $\text{sales} = 89.5978 + 0.1392\times\text{size} - 8.7379\times\text{num_bedrooms}$
- $Y = 89.5978 + 0.1392X_1 - 8.7379X_2$
:::


## Multiple Linear Regression: Prediction {.smaller}

- Prediction of `price` when `size` is 2000 square feet for a house with 3 bedrooms
- $\text{sales} = 89.5978 + 0.1392\times2000 - 8.7379\times3 = 341.7841$

. . .

```{r}
predict(mlr_model, newdata = data.frame(size = 2000, num_bedrooms = 3))   # obtain prediction
```
- Why don't these match exactly? [**rounding**]{.fragment .fade-in}


## Linear Regression: Comparing Models {.smaller}

:::{.fragment}
:::{.incremental}
- Many methods for comparing regression models from your regression course
- Today: Data splitting
- First: New Data
:::
:::
:::{.fragment}
- **ames housing data**
  + Many variables
  + Focus on:
    * `Sale_Price`: in dollars
    * `Gr_Liv_Area`: size in square feet
    * `Bedroom_AbvGr`: number of bedrooms above grade
:::



## Comparing Models: Data Splitting {.smaller}

- Split `ames` data set into two parts
  + Training set: randomly selected proportion $p$ (typically 50-90%) of data used for fitting model
  + Test set: randomly selected proportion $1-p$ of data used for estimating prediction error
- If comparing A LOT of models, split into *three* parts to prevent **information leakage**
  + Training set: randomly selected proportion $p$ (typically 50-90%) of data used for fitting model
  + Validation set: randomly selected proportion $q$ (typically 20-30%) of data used to choosing tuning parameters
  + Test set: randomly selected proportion $1-p-q$ of data used for estimating prediction error
- Idea: use data your model hasn't seen to get more accurate estimate of error and prevent overfitting

## Comparing Models: Data Splitting with R {.smaller}

```{r}
library(splitTools) # Load data splitting package
indicies <- partition(ames$Sale_Price, p = c(train = 0.7, test = 0.3)) # get indices of partitions
train_ames <- ames[indicies$train, ] # names will mimic above
test_ames <- ames[indicies$test, ]
```

- `partition` will actually stratify based on it's first argument (`Sales_Price` in this case)

## Linear Regression: Comparing Models {.smaller}

- Let's create three models with `Sale_Price` as the response:
  + **fit1**: a linear regression model with `Bedroom_AbvGr`  as the only predictor
  + **fit2**: a linear regression model with `Gr_Liv_Area` as the only predictor
  + **mlr_model** (similar to model in previous slides): a multiple regression model with `Gr_Liv_Area` and `Bedroom_AbvGr` as predictors
  
```{r}
fit1 <- lm(Sale_Price ~ Bedroom_AbvGr, data=train_ames) # Use only training set
fit2 <- lm(Sale_Price ~ Gr_Liv_Area, data = train_ames) 
mlr_model <- lm(Sale_Price ~ Gr_Liv_Area + Bedroom_AbvGr, data = train_ames)
```

## Computing Error Metrics {.smaller}

```{r}
# Fit 1
fit1_train_mse <- mean((train_ames$Sale_Price - predict(fit1))^2)
fit1_test_mse <- mean((test_ames$Sale_Price - predict(fit1, newdata = test_ames))^2)

# Fit 2
fit2_train_mse <- mean((train_ames$Sale_Price - predict(fit2))^2)
fit2_test_mse <- mean((test_ames$Sale_Price - predict(fit2, newdata = test_ames))^2)

# Fit 1
mlr_train_mse <- mean((train_ames$Sale_Price - predict(mlr_model))^2)
mlr_test_mse <- mean((test_ames$Sale_Price - predict(mlr_model, new_data = testames))^2)
```

## [Question]{style="color:blue"}

1. Do we know which of the following is the smallest: `fit1_train_mse`, `fit2_train_mse`, `mlr_train_mse`? [Yes, `mlr_train_mse`]{.fragment .fade-in}
2. Do we know which of the following is the smallest: `fit1_test_mse`, `fit2_test_mse`, `mlr_test_mse`? [No]{.fragment .fade-in}

## Choosing a Model {.smaller}

::::{.columns}
:::{.column}
```{r}
# Training Errors
fit1_train_mse
fit2_train_mse
mlr_train_mse
which.min(c(fit1_train_mse, fit2_train_mse, mlr_train_mse))

# test Errors
fit1_test_mse
fit2_test_mse
mlr_test_mse
which.min(c(fit1_test_mse, fit2_test_mse, mlr_test_mse))
```
:::
:::{.column}
- `mlr_model` has the lowest training MSE (to be expected)
- `fit2` has the lowest test MSE
  + We would choose `fit2`
- Anything else interesting we seee?
:::
::::


## Regression: Conditional Averaging

**Restaurant Outlets Profit dataset**

```{r}
#| echo: FALSE
outlets <- readRDS("outlets.rds")   # load dataset

ggplot(data = outlets, aes(x = population, y = profit)) +
  geom_point() +   # create scatterplot
  geom_smooth(method = "lm", se = FALSE)   # add the SLR line
```


What is a good value of $\hat{f}(x)$ (expected profit), say at $x=6$?

A possible choice is the **average of the observed responses** at $x=6$. But we may not observe responses for certain $x$ values.


## K-Nearest Neighbors (KNN) Regression  {.smaller}

- Non-parametric approach
- Formally: Given a value for $K$ and a test data point $x_0$,
$$\hat{f}(x_0)=\dfrac{1}{K} \sum_{x_i \in \mathcal{N}_0} y_i=\text{Average} \ \left(y_i \ \text{for all} \ i:\ x_i \in \mathcal{N}_0\right) $$
where $\mathcal{N}_0$ is the set of the $K$ training observations closest to $x_0$.
- Informally, average together the $K$ "closest" observations in your training set
- "Closeness": usually use the **Euclidean metric** to measure distance
- Euclidean distance between $\mathbf{X}_i=(x_{i1}, x_{i2}, \ldots, x_{ip})$ and $\mathbf{x}_j=(x_{j1}, x_{j2}, \ldots, x_{jp})$:
$$||\mathbf{x}_i-\mathbf{x}_j||_2 = \sqrt{(x_{i1}-x_{j1})^2 + (x_{i2}-x_{j2})^2 + \ldots + (x_{ip}-x_{jp    })^2}$$

## [KNN Regression (single predictor): Fit]{.r-fit-text} {.smaller}

::::{.columns}
:::{.column}
**$K=1$**
```{r}
library(caret)   # load the caret package
knnfit1 <- knnreg(profit ~ population, data = outlets, k = 1)   # 1-nn regression
predict(knnfit1, newdata = data.frame(population = 6))  # 1-nn prediction
```

```{r}
#| echo: FALSE
outlets |> 
  mutate(dist = abs(population - 6),
         is_knn = if_else(dist <= min(dist), TRUE, FALSE)) |>
  ggplot(aes(x = population, y = profit, color = is_knn)) +
  geom_point(size=3) +
  geom_vline(xintercept = 6) +
  theme(text = element_text(size = 20))
```


:::
:::{.column}
**$K=5$**
```{r}
knnfit5 <- knnreg(profit ~ population, data = outlets, k = 5)   # 5-nn regression
predict(knnfit5, newdata = data.frame(population = 6))  # 5-nn prediction
```

```{r}
#| echo: FALSE
outlets |> 
  mutate(dist = abs(population - 6),
         is_knn = if_else(dist <= nth(dist, n=-5), TRUE, FALSE)) |>
  ggplot(aes(x = population, y = profit, color = is_knn)) +
  geom_point(size = 3) +
  geom_vline(xintercept = 6) +
  theme(text = element_text(size = 20))
```
:::
::::

## Regression Methods: Comparison

```{r}
#| echo: FALSE

slrfit <- lm(profit ~ population, data = outlets)   # fit the SLR model
pop_seq <- seq(min(outlets$population, na.rm = TRUE), max(outlets$population, na.rm = TRUE), 0.01)

# obtain predictions for all training data points
knn_1 <- predict(knnfit1, newdata = data.frame(population = pop_seq))
knn_5 <- predict(knnfit5, newdata = data.frame(population = pop_seq))
p <-  predict(slrfit, newdata = data.frame(population = pop_seq))

# column bind original data with predicted values
predictions <- data.frame(population = pop_seq,
                          linear = p, knn_1, knn_5) |> 
  pivot_longer(cols = !population, names_to = "Method", values_to = "profit")


# plot the three models
ggplot(data = outlets, aes(x = population, y = profit)) +
  geom_point() +
  geom_line(data = predictions, aes(x = population, y = profit, color = Method, linetype = Method), linewidth = 1)
```


## <span style="color:blue">Question!!!</span>

As $K$ in KNN regression increases:

- the flexibility of the fit $\underline{\hspace{5cm}}$ ([increases]{.fragment .highlight-red} /decreases)
- the bias of the fit $\underline{\hspace{5cm}}$ (increases/[decreases]{.fragment .highlight-red} )
- the variance of the fit $\underline{\hspace{5cm}}$ ([increases]{.fragment .highlight-red}/decreases)


## [K-Nearest Neighbors Regression (multiple predictors)]{.r-fit-text} {.smaller}

- Let's look at the `house_prices` data
```{r}
#| echo: FALSE

ames |> 
  select(Sale_Price, Gr_Liv_Area, Bedroom_AbvGr) |> 
  head()
```
:::{.fragment}
:::{.incremental}
- Should 1 square foot count the same as 1 bedroom?
- Need to **center and scale** (freq. just say scale) 
  + subtract mean from each predictor
  + divide by standard deviation of each predictor
  + compares apples-to-apples
:::
:::

## Scaling in R

```{r}
# scale predictors
ames_scaled <- tibble(size_scaled = scale(ames$Gr_Liv_Area),
                                  num_bedrooms_scaled = scale(ames$Bedroom_AbvGr),
                                  price = ames$Sale_Price)

head(ames_scaled)   # first six observations
```


## [K-Nearest Neighbors Regression (multiple predictors)]{.r-fit-text} {.smaller}


```{r}
knnfit10 <- knnreg(price ~ size_scaled + num_bedrooms_scaled, data = ames_scaled, k = 10)   # 10-nn regression
```

- Must also scale test data points **using mean and sd from training set!!!!**
- Test Point: `size` = 2000 square feet, and `num_bedrooms` = 3, then

```{r}
# obtain 10-nn prediction

predict(knnfit10, newdata = tibble(size_scaled = (2000 - mean(ames$Gr_Liv_Area))/sd(ames$Gr_Liv_Area),
                                     num_bedrooms_scaled = (3 - mean(ames$Bedroom_AbvGr))/sd(ames$Bedroom_AbvGr)))
```


## [Linear Regression vs K-Nearest Neighbors]{.r-fit-text} {.smaller}

- Linear regression is a parametric approach (with restrictive assumptions), KNN is non-parametric.
- Linear regression works for regression problems ($Y$ numerical), KNN can be used for both regression and classification - i.e. $Y$ qualitative (next lesson)
- Linear regression is interpretable, KNN is not.
- Linear regression can accommodate qualitative predictors and can be extended to include interaction terms as well while KNN does not allow for qualitative predictors
- Performance: KNN can be pretty good for small $p$, that is, $p \le 4$ and large $n$. Performance of KNN deteriorates as $p$ increases - *curse of dimensionality*

<!-- ## Classification Problems {.smaller} -->

<!-- - Response $Y$ is qualitative (categorical). -->
<!-- - Objective: build a classifier $\hat{Y}=\hat{C}(\mathbf{X})$ -->
<!--   + assigns class label to a future unlabeled (unseen) observations  -->
<!--   + understand the relationship between the predictors and response -->
<!-- - Two ways to make predictions -->
<!--   + Class probabilities  -->
<!--   + Class labels -->

<!-- ## Classification Problems: Example -->

<!-- **Default dataset** -->

<!-- ```{r, message=FALSE} -->
<!-- library(ISLR2)   # load library -->
<!-- data("Default")   # load dataset -->
<!-- ``` -->

<!-- ```{r} -->
<!-- head(Default)   # print first six observations -->
<!-- ``` -->

<!-- ```{r,message=FALSE} -->
<!-- table(Default$default)   # class frequencies -->
<!-- ``` -->


<!-- **We will consider `default` as the response variable.** -->


<!-- ## Classification Problems: Example -->

<!-- For some algorithms, we might need to convert the categorical response to numeric (0/1) values. -->

<!-- **Default dataset** -->

<!-- ```{r,message=FALSE} -->
<!-- Default$default_id <- ifelse(Default$default == "Yes", 1, 0)   # create 0/1 variable -->

<!-- head(Default, 10)   # print first ten observations -->
<!-- ``` -->




<!-- ## K-Nearest Neighbors Classifier -->

<!-- Given a value for $K$ and a test data point $x_0$, -->
<!-- $$P(Y=j | X=x_0)=\dfrac{1}{K} \sum_{x_i \in \mathcal{N}_0} I(y_i = j)$$ -->

<!-- where $\mathcal{N}_0$ is known as the **neighborhood** of $x_0$. -->


<!-- For classification problems, the predictions are obtained in terms of **majority vote** (unlike in regression where predictions are obtained by averaging). -->


<!-- ## K-Nearest Neighbors Classifier: Build Model  -->

<!-- **Default dataset** -->

<!-- response ($Y$): `default` and predictor ($X$): `balance` -->

<!-- ```{r} -->
<!-- library(caret)   # load package 'caret' -->

<!-- knnfit <- knn3(default ~ balance, data = Default, k = 10)   # fit 10-nn model -->
<!-- ``` -->


<!-- ## K-Nearest Neighbors Classifier: Predictions  -->

<!-- **Default dataset** -->

<!-- * One can directly obtain the class label predictions as below. -->

<!-- ```{r} -->
<!-- knn_class_preds_1 <- predict(knnfit, newdata = Default, type = "class")   # obtain default class label predictions -->
<!-- ``` -->


<!-- * Otherwise, one can first obtain predictions in terms of probabilities and then convert them into class label predictions based on a threshold. -->

<!-- ```{r} -->
<!-- knn_prob_preds <- predict(knnfit, newdata = Default, type = "prob")   # obtain predictions as probabilities -->
<!-- ``` -->


<!-- ```{r} -->
<!-- threshold <- 0.5   # set threshold -->

<!-- knn_class_preds_2 <- factor(ifelse(knn_prob_preds[,2] > threshold, "Yes", "No"))   # obtain predictions as class labels -->
<!-- ``` -->


<!-- ## K-Nearest Neighbors Classifier: Performance  {.smaller} -->

<!-- **Default dataset** -->

<!-- ```{r} -->
<!-- # create confusion matrix -->

<!-- # use the following code only when all predictions are from the same class -->
<!-- # levels(knn_class_preds_1) = c("No", "Yes")  -->

<!-- confusionMatrix(data = knn_class_preds_1, reference = Default$default, positive = "Yes")    -->
<!-- ``` -->


